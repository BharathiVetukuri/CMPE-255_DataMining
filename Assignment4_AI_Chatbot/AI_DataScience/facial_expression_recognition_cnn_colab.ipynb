{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Facial Expression Recognition with CNNs using FER2013 Dataset\n", "This notebook implements a deep learning model for classifying facial expressions using the FER2013 dataset. We'll follow the CRISP-DM methodology, including downloading the dataset, preprocessing, building a CNN model, training, evaluation, and model improvements."]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["# Step 1: Install and Setup Kaggle API\n", "!pip install kaggle\n", "\n", "# Upload the kaggle.json file\n", "from google.colab import files\n", "files.upload()\n", "\n", "# Create Kaggle directory and move the kaggle.json file there\n", "!mkdir -p ~/.kaggle\n", "!cp kaggle.json ~/.kaggle/\n", "!chmod 600 ~/.kaggle/kaggle.json\n", "\n", "# Download the FER2013 dataset from Kaggle\n", "!kaggle datasets download -d msambare/fer2013\n", "\n", "# Unzip the dataset\n", "!unzip fer2013.zip"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["# Step 2: Data Understanding and Preprocessing\n", "import pandas as pd\n", "import numpy as np\n", "from sklearn.model_selection import train_test_split\n", "\n", "# Load the dataset\n", "data = pd.read_csv('fer2013.csv')\n", "print(data.head())  # Explore the first few rows\n", "print(data['emotion'].value_counts())  # Check the distribution of emotions\n", "\n", "# Preprocess the images\n", "def preprocess_data(data):\n", "    images = data['pixels'].str.split(\" \").tolist()\n", "    images = np.array(images, dtype=float).reshape(-1, 48, 48, 1)\n", "    images = images / 255.0  # Normalize pixel values to [0, 1]\n", "    labels = pd.get_dummies(data['emotion']).values  # One-hot encode the labels\n", "    return images, labels\n", "\n", "# Apply preprocessing\n", "images, labels = preprocess_data(data)\n", "\n", "# Split into training, validation, and test sets\n", "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n", "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["# Step 3: Build the CNN Model\n", "import tensorflow as tf\n", "from tensorflow.keras import layers, models\n", "\n", "# Build the CNN model\n", "model = models.Sequential([\n", "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)),\n", "    layers.MaxPooling2D((2, 2)),\n", "    layers.Conv2D(64, (3, 3), activation='relu'),\n", "    layers.MaxPooling2D((2, 2)),\n", "    layers.Conv2D(128, (3, 3), activation='relu'),\n", "    layers.MaxPooling2D((2, 2)),\n", "    layers.Flatten(),\n", "    layers.Dense(128, activation='relu'),\n", "    layers.Dropout(0.5),\n", "    layers.Dense(7, activation='softmax')  # 7 emotion classes\n", "])\n", "\n", "# Compile the model\n", "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n", "model.summary()  # Display the model's architecture"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": ["# Step 4: Train the Model\n", "history = model.fit(X_train, y_train, epochs=30, batch_size=64, validation_data=(X_val, y_val))"]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": ["# Step 5: Evaluate the Model and Plot Confusion Matrix\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "from sklearn.metrics import confusion_matrix\n", "\n", "# Evaluate the model\n", "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n", "print(f\"Test accuracy: {test_acc}\")\n", "\n", "# Predict the labels for the test set\n", "y_pred = np.argmax(model.predict(X_test), axis=1)\n", "y_true = np.argmax(y_test, axis=1)\n", "\n", "# Plot confusion matrix\n", "cm = confusion_matrix(y_true, y_pred)\n", "plt.figure(figsize=(10, 7))\n", "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral'],\n", "            yticklabels=['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral'])\n", "plt.xlabel('Predicted')\n", "plt.ylabel('True')\n", "plt.show()"]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": ["# Step 6: Improving the Model (Optional)\n", "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n", "\n", "# Data Augmentation\n", "datagen = ImageDataGenerator(\n", "    rotation_range=20,\n", "    zoom_range=0.2,\n", "    width_shift_range=0.2,\n", "    height_shift_range=0.2,\n", "    horizontal_flip=True\n", ")\n", "\n", "# Apply augmentation\n", "datagen.fit(X_train)\n", "\n", "# Retrain the model with augmented data\n", "history_augmented = model.fit(datagen.flow(X_train, y_train, batch_size=64), epochs=30, validation_data=(X_val, y_val))"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python"}}, "nbformat": 4, "nbformat_minor": 4}